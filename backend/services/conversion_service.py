import os
import sys
import logging
import threading
from flask import current_app

from ..extensions import db
from ..models.conversion import ConversionTask, ConvertedDataset
from ..data_extractor import extract_water_flow_data

def run_conversion_in_thread(app, task_id):
    """Worker function to run in a background thread."""
    with app.app_context():
        task = ConversionTask.query.get(task_id)
        if not task:
            logging.error(f"ConversionTask with ID {task_id} not found.")
            return

        original_dataset = task.original_dataset
        if not original_dataset:
            logging.error(f"Original dataset not found for ConversionTask {task_id}")
            task.status = 'failed'
            db.session.commit()
            return
        
        # Define paths
        project_root = os.path.abspath(os.path.join(current_app.root_path, '..'))
        
        # Construct the full, absolute path to the source Excel file
        # original_dataset.file_path only stores the filename, so we join it with the UPLOAD_FOLDER
        source_excel_path = os.path.join(project_root, 'uploads', original_dataset.file_path)
        
        output_dir = os.path.join(project_root, 'converted_datasets', str(task.id))
        
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            task.status = 'processing'
            db.session.commit()

            if not extract_water_flow_data:
                raise RuntimeError("data_extractor module could not be imported.")

            logging.info(f"Starting conversion for {source_excel_path}, output to {output_dir}")
            
            # This is a blocking call. It will run the extraction logic.
            success = extract_water_flow_data(source_excel_path, output_dir)
            
            if not success:
                raise RuntimeError("extract_water_flow_data function returned False.")

            # Scan output directory for generated CSV files
            generated_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]

            if not generated_files:
                raise RuntimeError("No CSV files were generated by the script.")

            for filename in generated_files:
                file_path = os.path.join(output_dir, filename)
                file_size = os.path.getsize(file_path)
                
                # Use filename without .csv as the name (e.g., '1æ ‹')
                dataset_name = os.path.splitext(filename)[0]

                new_converted_dataset = ConvertedDataset(
                    name=dataset_name,
                    file_path=file_path,
                    file_size=file_size,
                    task_id=task.id
                )
                db.session.add(new_converted_dataset)
            
            task.status = 'completed'
            logging.info(f"Conversion task {task.id} completed successfully.")

        except Exception as e:
            task.status = 'failed'
            logging.error(f"Conversion task {task.id} failed: {str(e)}", exc_info=True)
        
        finally:
            db.session.commit()

def start_conversion_task(dataset):
    """Creates a conversion task and starts it in a background thread."""
    
    new_task = ConversionTask(
        original_dataset_id=dataset.id,
        status='pending'
    )
    
    try:
        db.session.add(new_task)
        db.session.commit()

        app = current_app._get_current_object()
        thread = threading.Thread(target=run_conversion_in_thread, args=(app, new_task.id))
        thread.daemon = True
        thread.start()
        
        logging.info(f"Started conversion task {new_task.id} for dataset {dataset.id}")
        
        return new_task

    except Exception as e:
        db.session.rollback()
        logging.error(f"Failed to create conversion task for dataset {dataset.id}: {e}", exc_info=True)
        return None 